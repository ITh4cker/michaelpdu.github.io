# Adversarial Machine Learning

## Conferences
* [Evading Machine Learning Malware Detection](https://www.blackhat.com/docs/us-17/thursday/us-17-Anderson-Bot-Vs-Bot-Evading-Machine-Learning-Malware-Detection-wp.pdf), Anderson et al., Blackhat US 2017

  Use Reinforcement Learning to evade Machine Learning model, but don't break functionality.

* [EvadeML](http://evademl.org/gpevasion/), Weilin Xu, USENIX Enigma 2017

  Use Genetic Algorithm to generate evasive samples to bypass PDF detection model.

## Papers
* [Adversarial Examples Are Not Easily Detected](https://arxiv.org/pdf/1705.07263.pdf), Nicholas Carlini and David Wagner, University of California, Berkeley
* [On the (Statistical) Detection of Adversarial Examples](https://arxiv.org/pdf/1702.06280.pdf), Kathrin Grosse, et al., Penn State University

## Blogs
* [Attacking Machine Learning with Adversarial Examples](https://blog.openai.com/adversarial-example-research/)
* [对深度学习的逃逸攻击 — 探究人工智能系统中的安全盲区](http://bobao.360.cn/learning/detail/4569.html)
* [深度学习框架中的魔鬼 — 探究人工智能系统中的安全问题](http://blogs.360.cn/blog/devils-in-the-deep-learning-framework/)

## Other Summary
* [Awesome Adversarial Machine Learning](https://github.com/yenchenlin/awesome-adversarial-machine-learning),  yenchenlin's summary

